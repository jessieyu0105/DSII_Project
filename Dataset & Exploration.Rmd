---
title: "Dataset & Exploration"
author: "Jie Yu"
date: 2019-03-26
output: html_document
---

```{r setup, include = TRUE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  message = F,
  warning = F
  ) 

library(tidyverse)
library(readxl)
library(stringr)
```

### Generate resulting dataset

First, make a catalogue

```{r}
catalogue =  read_excel("./data/CHSI_DataSet.xlsx", sheet = "DATAELEMENTDESCRIPTION") %>% 
  janitor::clean_names() %>%
  # pick out "County data"
  mutate(county_data = ifelse(str_detect(.$description, c("[Cc]ounty data")) == TRUE, 1, 0)) %>% 
  filter(county_data == 1) %>% 
  # select the categories of variables which we want to use
  filter(page_name %in% c("Demographics", "SummaryMeasuresOfHealth", "RiskFactorsAndAccessToCare", "VunerablePopsAndEnvHealth")) %>% 
  filter(
    !str_detect(column_name, c("^Ecol")),
    !str_detect(column_name, c("^Salm")),
    !str_detect(column_name, c("^Shig")),
    !str_detect(column_name, c("^Toxic"))
  )
```

Select variables from different datasets based on our catalogue

```{r warning = FALSE, message = FALSE}
demographics = read.csv("./data/Demographics.csv")

# select columns from the dataframe based on variables from another dataframe
tbl_1 = read.csv("./data/Demographics.csv") %>% 
  select(one_of(dput(as.character(catalogue$column_name))))

tbl_2 = read.csv("./data/SummaryMeasuresOfHealth.csv") %>% 
  select(one_of(dput(as.character(catalogue$column_name))))

tbl_3 = read.csv("./data/RiskFactorsAndAccessToCare.csv") %>% 
  select(one_of(dput(as.character(catalogue$column_name))))

tbl_4 = read.csv("./data/VunerablePopsAndEnvHealth.csv") %>% 
  select(one_of(dput(as.character(catalogue$column_name))))

data = cbind(tbl_1, tbl_2, tbl_3, tbl_4)

# add identifiers
data = cbind(demographics$CHSI_County_Name, demographics$CHSI_State_Abbr, data) %>% 
  rename(county_name = 'demographics$CHSI_County_Name',
         state_abbr = 'demographics$CHSI_State_Abbr') %>% 
  janitor::clean_names() %>% 
  # Take out the response 'ale'
  select(ale, everything())
```

Look at our resulting dataset:

```{r}
names(data)

skimr::skim(data)
```

```{r eval = F}
write.csv(data, file = "./data/data.csv")
```


### Deal with Missing Data

```{r}
data.try = data

# List of missing value (see `CHSI_DataSet.csv)
list = c(-9999, -2222, -2222.2, -2, -1111.1, -1111, -1)

for (i in 1:length(list)) {
  data.try[ data.try == list[i] ] <- NA
}

# Re-check
sapply(data.try[1:ncol(data.try)], function(x) {list %in% x}) %>% 
  sum() # all the missing values have been re-written as NA

# See: which variables have NA
sapply(data.try[1:ncol(data.try)], function(x) sum(length(which(is.na(x)))))

percentage_NA <- sapply(data.try[1:ncol(data.try)], function(x) sum(length(which(is.na(x)))) / nrow(data.try) * 100)

percentage_NA 
```

Extract all the variables with NA -> data.NA

```{r}
for (i in 1:length(percentage_NA)) {
    if (percentage_NA[i] > 0) {
         print(percentage_NA[i]) # value with name
    } 
}

list_NA <- percentage_NA[which(percentage_NA > 0)] %>% 
  names()

data.NA = data.try %>% 
  select(one_of(dput(as.character(list_NA))))
```

Check if there are percentage_NA > 30%

```{r}
# method 1
percentage_NA[which(percentage_NA > 30)]

# method 2
for (i in 1:length(percentage_NA)) {
    if (percentage_NA[i] > 30) {
        print(percentage_NA[i]) # value with name
    } 
}
```

`few_fruit_veg` and `high_blood_pres` has missing data > 30%, so we drop them.

```{r}
data.NA = data.NA %>% 
  select(-few_fruit_veg, -high_blood_pres )

data.try = data.try %>% 
  select(-few_fruit_veg, -high_blood_pres )
```

Draw the histograms for all the variables with NA:

```{r}
data.NA %>% gather() %>% head()

# subset(data, !is.na(variable)): Eliminating NAs from a ggplot
ggplot(subset(gather(data.NA), !is.na(value)), aes(value)) + 
    geom_histogram(bins = 10) + 
    facet_wrap(~key, scales = 'free_x')
```

Approximately normal: ale, all_death, diabetes, health_status, no_exercise, obesity, poverty, smoker, unhealth_days  

Mean imputation for these approximately normal variables:

```{r}
normal_list <- c('ale', 'all_death', 'diabetes', 'health_status', 'no_exercise', 'obesity', 'poverty', 'smoker', 'unhealthy_days')

normal_dataset = data.NA %>% 
  select(one_of(dput(as.character(normal_list))))

for(i in 1:ncol(normal_dataset)){
  normal_dataset[is.na(normal_dataset[,i]), i] <- mean(normal_dataset[,i], na.rm = TRUE)
}

# Check
sum(is.na(normal_dataset)) # no NA
```

Median imputation for other skewed variables:

```{r}
# L[!(L %in% L1)]
skew_list <- names(data.NA)[!(names(data.NA) %in% normal_list)]
skew_list

skew_dataset = data.NA %>% 
  select(one_of(dput(as.character(skew_list))))

for(i in 1:ncol(skew_dataset)){
  skew_dataset[is.na(skew_dataset[,i]), i] <- median(skew_dataset[,i], na.rm = TRUE)
}

# Check
sum(is.na(skew_dataset)) # no NA
```

Generating resulting dataset with no NAs: `dataset`

```{r}
no_NA_list <- names(data.try)[!(names(data.try) %in% names(data.NA))]
no_NA_list

no_NA_dataset = data.try %>% 
  select(one_of(dput(as.character(no_NA_list))))

dataset = cbind(no_NA_dataset, normal_dataset, skew_dataset)
```

### Correlation plot

```{r}
library(corrplot)

dataset_1 = dataset %>% 
  select(-county_name, -state_abbr)

x = model.matrix(ale ~., dataset_1)[,-1]
corrplot(cor(x), method = "number", number.cex = 0.5, tl.cex = 0.8)

cor(dataset_1)
```

